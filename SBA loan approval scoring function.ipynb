{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e40daacb",
   "metadata": {},
   "source": [
    "# Scoring function for SBA loan approval model\n",
    "We will create a scoring function for the SBA loan approval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "683834b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_1_scoring(data):\n",
    "    \n",
    "    '''Returns model performance scores given a dataset'''\n",
    "    import pandas as pd\n",
    "    pd.set_option('display.max_columns', 1500)\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    #Extend cell width\n",
    "    from IPython.core.display import display, HTML\n",
    "    display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "    \n",
    "    import numpy as np\n",
    "    import category_encoders as ce\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import pickle\n",
    "\n",
    "    \n",
    "    # Convert dataset to pandas dataframe\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    \n",
    "    # Drop MIS_Status column if it exists\n",
    "    if 'MIS_Status' in data.columns: \n",
    "        data.drop('MIS_Status', axis=1, inplace=True)\n",
    "        \n",
    "    # Load Artifacts:\n",
    "    with open(\"TTK210000_artifacts_dict.pkl\", \"rb\") as f:\n",
    "        TTK210000_artifacts_dict = pickle.load(f)\n",
    "        \n",
    "    # Access the contents of the dictionary\n",
    "        best_lreg = TTK210000_artifacts_dict[\"model\"]\n",
    "        ohe = TTK210000_artifacts_dict[\"one_hot_encoder\"]\n",
    "        woe_encoder = TTK210000_artifacts_dict[\"woe_encoder\"]\n",
    "        scaler = TTK210000_artifacts_dict[\"Min_Max_Scaler\"]\n",
    "        best_threshold = TTK210000_artifacts_dict[\"threshold\"]\n",
    "\n",
    "    # Convert the strings styled as '$XXXX.XX' to float values.\n",
    "    float_nums = ['DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n",
    "    for column in float_nums:\n",
    "        data[column] = pd.to_numeric(data[column].str.replace('$', '').str.replace(',', ''))\n",
    "        \n",
    "    #Numeric and Categorical Columns\n",
    "    num_cols = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    cat_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Filling Numeric column with 0\n",
    "    data[num_cols]=data[num_cols].fillna(0)\n",
    "    \n",
    "    # Filling categorical columns with \"Missing\"\n",
    "    data[cat_cols] = data[cat_cols].fillna(\"Missing\")\n",
    "    \n",
    "    # Feature Engineering to add 10 new features\n",
    "    \n",
    "    # Feature 1: OutstandingBalance - ratio of BalanceGross and DisbursementGross\n",
    "    data['OutstandingBalance'] = data['BalanceGross'] / data['DisbursementGross']\n",
    "    \n",
    "    # Feature 2: IsFranchise - Convert 0 for not franchise and 1 for franchise\n",
    "    data['IsFranchise'] = data['FranchiseCode'].apply(lambda x: 0 if x in [0, 1] else 1)\n",
    "    data = data.drop('FranchiseCode', axis=1)\n",
    "    \n",
    "    # Feature 3: SBAAppvRate - how much of Gross approved amount is SBA approved\n",
    "    data['SBAAppvRate'] = data['SBA_Appv'] / data['GrAppv']\n",
    "    \n",
    "    # Feature 4: DisbursementRate - how much of approved amount was disbursed\n",
    "    data['DisbursementRate'] = data['DisbursementGross'] / data['GrAppv']\n",
    "    \n",
    "    # Feature 5: JobLoss - Job Loss will be 1, and no job loss will be 0\n",
    "    data['JobLoss'] = data['NoEmp'] + data['CreateJob'] - data['RetainedJob']\n",
    "    data['JobLoss'] = data['JobLoss'].apply(lambda x: 1 if x < 0 else 0 )\n",
    "    \n",
    "    # Feature 6: Categorize short, medium, long term loans \n",
    "    data['ShortTerm'] = data['Term'].apply(lambda x: 1 if x < 18 else 0)\n",
    "    data['MediumTerm'] = data['Term'].apply(lambda x: 1 if 18 <= x <= 60 else 0)\n",
    "    data['LongTerm'] = data['Term'].apply(lambda x: 1 if x > 60 else 0)\n",
    "    data = data.drop(['Term'], axis=1)\n",
    "    \n",
    "    # Feature 7: Categorize based on loan size - small, medium and large loan\n",
    "    data['SmallLoan'] = data['DisbursementGross'].apply(lambda x: 1 if x < 100000 else 0)\n",
    "    data['MediumLoan'] = data['DisbursementGross'].apply(lambda x: 1 if 100000 <= x <= 450000 else 0)\n",
    "    data['LargeLoan'] = data['DisbursementGross'].apply(lambda x: 1 if x > 450000 else 0)\n",
    "    \n",
    "    # Feature 8: SameState - checks if Bank is in the same state as the lender bank\n",
    "    data['SameState'] = data.apply(lambda x: 0 if x['State'] == x['BankState'] else 1, axis = 1)\n",
    "    \n",
    "    # Feature 9: Industry -take first 2 digits of NAICS code\n",
    "    data['Industry'] = data['NAICS'].astype('str').apply(lambda x: x[:2])\n",
    "    data = data.drop('NAICS', axis=1)\n",
    "    \n",
    "    # Feature 10: Regions - Map states into Northeast, Midwest, South, West\n",
    "    \n",
    "    # Create region mapping function\n",
    "    def map_region(state):\n",
    "        if state in ['CT', 'ME', 'MA', 'NH', 'RI', 'VT', 'NJ', 'NY', 'PA']:\n",
    "            return 'Northeast'\n",
    "        elif state in ['IL', 'IN', 'IA', 'KS', 'MI', 'MN', 'MO', 'NE', 'ND', 'OH', 'SD', 'WI']:\n",
    "            return 'Midwest'\n",
    "        elif state in ['AL', 'AR', 'DE', 'FL', 'GA', 'KY', 'LA', 'MD', 'MS', 'NC', 'OK', 'SC', 'TN', 'TX', 'VA', 'WV']:\n",
    "            return 'South'\n",
    "        elif state in ['AK', 'AZ', 'CA', 'CO', 'HI', 'ID', 'MT', 'NV', 'NM', 'OR', 'UT', 'WA', 'WY']:\n",
    "            return 'West'\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "    # Map regions into dataset \n",
    "    data['Region'] = data['State'].apply(map_region)\n",
    "    \n",
    "        \n",
    "    # WOE encoding\n",
    "    woe_cols = ['City','State','Bank','BankState','RevLineCr','Industry']\n",
    "    \n",
    "    # transform data to WOE encoding\n",
    "    \n",
    "    data_woe = woe_encoder.transform(data)\n",
    "    \n",
    "    # Rename the WOE encoded columns:\n",
    "    \n",
    "    data_woe.rename(columns={'City':'City_woe', 'State':'State_woe', 'Bank':'Bank_woe',\n",
    "                           'BankState':'BankState_woe', 'RevLineCr':'RevLineCr_woe',\n",
    "                           'Industry':'Industry_woe'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Add the WOE Encoded column to original dataset\n",
    "    data[['City_woe', 'State_woe', 'Bank_woe', 'BankState_woe',\n",
    "        'RevLineCr_woe','Industry_woe']]=data_woe[['City_woe', 'State_woe', 'Bank_woe', 'BankState_woe',\n",
    "                                               'RevLineCr_woe','Industry_woe']]\n",
    "    \n",
    "    \n",
    "    # Drop the original columns\n",
    "    data = data.drop(columns = ['City','State','Bank','BankState','RevLineCr'])\n",
    "           \n",
    "    # One hot encoding\n",
    "    cols_to_encode = ['LowDoc', 'Region']\n",
    "    \n",
    "    # transform one hot encoder on dataset \n",
    "    new_col_names = ohe.transform(data[cols_to_encode]).astype(int).astype(str)\n",
    "    new_col_names = [col + '_' + name for col, names in zip(cols_to_encode, ohe.categories_) for name in names]\n",
    "    \n",
    "    #Apply OHE to dataframe\n",
    "    ohe_encoded = pd.DataFrame(ohe.transform(data[cols_to_encode]).astype(int), columns=new_col_names, index=data.index)\n",
    "    \n",
    "    # add encoded columns to original dataset\n",
    "    data = pd.concat([data, ohe_encoded], axis=1)\n",
    "    \n",
    "    # drop the original columns\n",
    "    data = data.drop(columns=cols_to_encode)\n",
    "    \n",
    "    # Drop index column\n",
    "    record_id = data['index']\n",
    "    data = data.drop('index', axis = 1)\n",
    "    \n",
    "    data = data.astype({'Zip':'str', 'NewExist': 'int64'})\n",
    "    \n",
    "    # Fill NA values after encoding\n",
    "    values_to_fill = {}\n",
    "    for col in data.columns:\n",
    "        if pd.api.types.is_numeric_dtype(data[col].dtype):\n",
    "            values_to_fill[col] = 0\n",
    "        else:\n",
    "            values_to_fill[col] = \"Missing\"\n",
    "        \n",
    "    data.fillna(value=values_to_fill,inplace=True)\n",
    "\n",
    "    # Scaling dataset\n",
    "    scaler_cols = ['NoEmp','CreateJob','RetainedJob','DisbursementGross','BalanceGross','GrAppv','SBA_Appv']\n",
    "    \n",
    "    \n",
    "    # transform\n",
    "    data_scaled = scaler.transform(data[scaler_cols])\n",
    "    \n",
    "    \n",
    "    # Convert to dataframe\n",
    "    scaled_data = pd.DataFrame(data_scaled,\n",
    "                             columns=['NoEmp_scaled','CreateJob_scaled','RetainedJob_scaled',\n",
    "                                      'DisbursementGross_scaled','BalanceGross_scaled',\n",
    "                                      'GrAppv_scaled','SBA_Appv_scaled'])\n",
    "    \n",
    "    \n",
    "    # add scaled columns to original dataset\n",
    "    data= pd.concat([data.reset_index(drop=True),scaled_data], axis =1)\n",
    "    \n",
    "    \n",
    "    # drop the original columns\n",
    "    data = data.drop(columns=scaler_cols)\n",
    "       \n",
    "    # Get the probability threshold to maximize F1 on the dataset\n",
    "    y_pred = (best_lreg.predict_proba(data)[:,1] >=best_threshold).astype(int)\n",
    "    y_pred_proba = best_lreg.predict_proba(data)\n",
    "    \n",
    "    d = {\"index\": record_id,\n",
    "         \"label\":y_pred,\n",
    "         \"probability_0\":y_pred_proba[:,0],\n",
    "         \"probability_1\":y_pred_proba[:,1]}\n",
    "    \n",
    "    return pd.DataFrame(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316ae5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sba_df = pd.read_csv('SBA_loans_project_1.zip')\n",
    "\n",
    "sba_df = sba_df.sample(frac=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4054ffbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>probability_0</th>\n",
       "      <th>probability_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198206</th>\n",
       "      <td>198206</td>\n",
       "      <td>1</td>\n",
       "      <td>0.525320</td>\n",
       "      <td>0.474680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364208</th>\n",
       "      <td>364208</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948636</td>\n",
       "      <td>0.051364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17505</th>\n",
       "      <td>17505</td>\n",
       "      <td>1</td>\n",
       "      <td>0.569269</td>\n",
       "      <td>0.430731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258624</th>\n",
       "      <td>258624</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977369</td>\n",
       "      <td>0.022631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29264</th>\n",
       "      <td>29264</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982075</td>\n",
       "      <td>0.017925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732986</th>\n",
       "      <td>732986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.807468</td>\n",
       "      <td>0.192532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620999</th>\n",
       "      <td>620999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.466503</td>\n",
       "      <td>0.533497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86520</th>\n",
       "      <td>86520</td>\n",
       "      <td>1</td>\n",
       "      <td>0.388222</td>\n",
       "      <td>0.611778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753077</th>\n",
       "      <td>753077</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945775</td>\n",
       "      <td>0.054225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669359</th>\n",
       "      <td>669359</td>\n",
       "      <td>0</td>\n",
       "      <td>0.778446</td>\n",
       "      <td>0.221554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40462 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  label  probability_0  probability_1\n",
       "198206  198206      1       0.525320       0.474680\n",
       "364208  364208      0       0.948636       0.051364\n",
       "17505    17505      1       0.569269       0.430731\n",
       "258624  258624      0       0.977369       0.022631\n",
       "29264    29264      0       0.982075       0.017925\n",
       "...        ...    ...            ...            ...\n",
       "732986  732986      0       0.807468       0.192532\n",
       "620999  620999      1       0.466503       0.533497\n",
       "86520    86520      1       0.388222       0.611778\n",
       "753077  753077      0       0.945775       0.054225\n",
       "669359  669359      0       0.778446       0.221554\n",
       "\n",
       "[40462 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_1_scoring(sba_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
